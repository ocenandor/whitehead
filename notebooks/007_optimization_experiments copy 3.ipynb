{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/main/whitehead\n"
     ]
    }
   ],
   "source": [
    "cd whitehead/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/tmp/ipykernel_402184/2135595585.py:13: DeprecationWarning: /usr/local/lib/python3.10/site-packages/ignite/contrib/handlers/tqdm_logger.py has been moved to /ignite/handlers/tqdm_logger.py and will be removed in version 0.6.0.\n",
      " Please refer to the documentation for more details.\n",
      "  from ignite.contrib.handlers.tqdm_logger import ProgressBar\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import itertools\n",
    "import pickle\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from uuid import uuid1\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers.tensorboard_logger import *\n",
    "from ignite.handlers.wandb_logger import *\n",
    "from ignite.metrics import Accuracy\n",
    "from lming.utils import download_artifact\n",
    "from schedulefree import SGDScheduleFree, AdamWScheduleFree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tokenizer import build_tokenizer\n",
    "from torch.optim import SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, BertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = build_tokenizer('word-level', fdim=3, add_commutator_tokens=True,\n",
    "                            add_prompt_tokens=True, add_post_processor=True)\n",
    "\n",
    "config = BertConfig(\n",
    "    vocab_size = len(tokenizer.get_vocab()),\n",
    "    hidden_size = 768,\n",
    "    num_hidden_layers = 8,\n",
    "    num_attention_heads = 6,\n",
    "    intermediate_size = 512,\n",
    "    num_labels=2,\n",
    "    bos_token_id = tokenizer.bos_token_id,\n",
    "    eos_token_id = tokenizer.eos_token_id,\n",
    "    pad_token_id = tokenizer.pad_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpavel-tikhomirov\u001b[0m (\u001b[33mml-in-algebraic-topology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/main/whitehead/pavel-tikhomirov-runs/wandb/run-20241211_224519-0euyaids</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/0euyaids' target=\"_blank\">curious-breeze-306</a></strong> to <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/0euyaids' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/0euyaids</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact fdim-3-whitehead:v4, 167.68MB. 3 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "Done. 0:0:0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fae4226aab40d5950ec4e1494c7c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">curious-breeze-306</strong> at: <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/0euyaids' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/0euyaids</a><br/> View project at: <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./pavel-tikhomirov-runs/wandb/run-20241211_224519-0euyaids/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "environ['WANDB_USERNAME']='pavel-tikhomirov'\n",
    "environ['WANDB_DIR']=f'/main/whitehead/{environ[\"WANDB_USERNAME\"]}-runs/'\n",
    "environ['TOKENIZERS_PARALLELISM']='false'\n",
    "\n",
    "run = wandb.init(entity='ml-in-algebraic-topology', project='whitehead')\n",
    "artifact_dir = download_artifact('fdim-3-whitehead:v4')\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 800000/800000 [00:03<00:00, 263499.83it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(Path(artifact_dir) / \"train.pkl\", 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(Path(artifact_dir) / \"val.pkl\", 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "\n",
    "data = train_data + val_data\n",
    "\n",
    "def process_word(word):\n",
    "    return {\n",
    "        'word_str': word['word_str'].split(':')[1],\n",
    "        'label': int(word['label'] == 'c'),\n",
    "        'len': len(word['word_str'].split(':')[1].split())\n",
    "        }\n",
    "\n",
    "data_processed = list(map(process_word, tqdm(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 199156/199156 [00:00<00:00, 235694.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 600844/600844 [00:02<00:00, 270944.05it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_processed = list(map(process_word, tqdm(train_data)))\n",
    "val_data_processed = list(map(process_word, tqdm(val_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_processed)\n",
    "df_train = pd.DataFrame(train_data_processed)\n",
    "df_val = pd.DataFrame(val_data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_com_length = df[['label', 'len']].groupby('label').min().loc[1].item()\n",
    "max_common_length = df[['label', 'len']].groupby('label').max().min().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN_THRESHOLD = 90\n",
    "test_no_com_small_length = df[df.len < min_com_length]\n",
    "df_main = df_train[df_train.len <= MAX_LEN_THRESHOLD]\n",
    "test_big_length = df_train[df_train.len > MAX_LEN_THRESHOLD]\n",
    "test_only_com = df_val[df_val.len > max_common_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df_main, stratify=df_main.label, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.df.iloc[index].to_dict()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_classification_train(batch):\n",
    "    collated_batch = tokenizer([el['word_str'] for el in batch],\n",
    "                      padding=True, return_tensors='pt',\n",
    "                      return_token_type_ids=False)\n",
    "    collated_batch['labels'] = torch.tensor([el['label'] for el in batch])\n",
    "    return collated_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train)\n",
    "val_dataset = CustomDataset(val)\n",
    "test_no_com_small_length_dataset = CustomDataset(test_no_com_small_length)\n",
    "test_big_length_dataset = CustomDataset(test_big_length)\n",
    "test_only_com_dataset = CustomDataset(test_only_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=256, collate_fn=collate_classification_train, shuffle=False)\n",
    "\n",
    "test_no_com_small_length_dataloader = DataLoader(test_no_com_small_length_dataset, batch_size=256, collate_fn=collate_classification_train, shuffle=False)\n",
    "test_big_length_dataloader = DataLoader(test_big_length_dataset, batch_size=256, collate_fn=collate_classification_train, shuffle=False)\n",
    "test_only_com_dataloader = DataLoader(test_only_com_dataset, batch_size=256, collate_fn=collate_classification_train, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop (for every optmizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(engine, batch):\n",
    "    model.train()\n",
    "    if hasattr(optimizer, \"train\"):\n",
    "        optimizer.train()\n",
    "    result = model(**batch.to(device))\n",
    "    loss = criterion(result.logits, batch['labels'])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "\n",
    "    return {\n",
    "        'loss': loss.item(),\n",
    "        'logits': result.logits.detach().cpu(),\n",
    "        'y_true': batch['labels'].detach().cpu(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(engine, batch):\n",
    "    model.eval()\n",
    "    if hasattr(optimizer, \"eval\"):\n",
    "        optimizer.eval()\n",
    "    with torch.no_grad():\n",
    "        result = model(**batch.to(device))\n",
    "        loss = criterion(result.logits, batch['labels'])\n",
    "        \n",
    "    return {\n",
    "        'loss': loss.item(),\n",
    "        'logits': result.logits.detach().cpu(),\n",
    "        'y_true': batch['labels'].detach().cpu(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_transform(output):\n",
    "    _, y_pred = torch.max(output['logits'], 1)\n",
    "    y = output['y_true']\n",
    "    return y_pred, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_meta(model, optimizer, log_suffix=str(uuid1()), config={}):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                  batch_size=config['batch_size'],\n",
    "                                  collate_fn=collate_classification_train,\n",
    "                                  shuffle=True)\n",
    "\n",
    "    engines = [\n",
    "        ('train', Engine(train), train_dataloader),\n",
    "        ('val', Engine(validation), val_dataloader),\n",
    "        ('small_length_no_comm_test', Engine(validation), test_no_com_small_length_dataloader),\n",
    "        ('big_length_joint_test', Engine(validation), test_big_length_dataloader),\n",
    "        ('big_length_only_comm_test', Engine(validation), test_only_com_dataloader)\n",
    "    ]\n",
    "    engines = [dict(zip(['name', 'engine', 'dataloader'], engine)) for engine in engines]\n",
    "\n",
    "    TB_LOGGER = TensorboardLogger(log_dir=f\"./experiments/{log_suffix}\")\n",
    "    WANDB_LOGGER = WandBLogger(\n",
    "        entity='ml-in-algebraic-topology',\n",
    "        project='whitehead',\n",
    "        config=config,\n",
    "        tags=[\"optimization\", \"na_zachet\", \"batch_size\"],\n",
    "        job_type='train'\n",
    "    )\n",
    "\n",
    "    for engine in engines:\n",
    "        if engine['name'] == 'train':\n",
    "            TB_LOGGER.attach_output_handler(\n",
    "                engine['engine'],\n",
    "                event_name=Events.ITERATION_COMPLETED(every=10),\n",
    "                tag=f'loss/{engine[\"name\"]}',\n",
    "                output_transform = lambda output: output['loss']\n",
    "            )\n",
    "            WANDB_LOGGER.attach(\n",
    "                engine['engine'],\n",
    "                log_handler=OutputHandler(\n",
    "                    tag=f'loss/{engine[\"name\"]}',\n",
    "                    output_transform = lambda output: output['loss'],\n",
    "                ),\n",
    "                event_name=Events.ITERATION_COMPLETED(every=10)\n",
    "            )\n",
    "        Accuracy(output_transform=output_transform).attach(engine['engine'], \"accuracy\")\n",
    "\n",
    "        TB_LOGGER.attach_output_handler(\n",
    "            engine['engine'],\n",
    "            event_name=Events.EPOCH_COMPLETED,\n",
    "            tag=f'accuracy/{engine[\"name\"]}',\n",
    "            metric_names=[\"accuracy\"],\n",
    "            global_step_transform=global_step_from_engine(engines[0]['engine']),\n",
    "        )\n",
    "        WANDB_LOGGER.attach(\n",
    "            engine['engine'],\n",
    "            log_handler=OutputHandler(\n",
    "                tag=f'accuracy/{engine[\"name\"]}',\n",
    "                metric_names = [\"accuracy\"],\n",
    "                global_step_transform=lambda *_: engines[0]['engine'].state.iteration\n",
    "            ),\n",
    "            event_name=Events.EPOCH_COMPLETED\n",
    "        )\n",
    "\n",
    "    ProgressBar().attach(engines[0]['engine'], output_transform = lambda output: {\"loss\": output['loss']})\n",
    "\n",
    "    def run_tests():\n",
    "        ### https://github.com/facebookresearch/schedule_free#:~:text=Examples%20Repo.-,Caveats,-If%20your%20model\n",
    "        if hasattr(optimizer, \"eval\"):\n",
    "            model.train()\n",
    "            optimizer.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch in itertools.islice(train_dataloader, 25):\n",
    "                    model(**batch.to(device))\n",
    "            model.eval()\n",
    "        ###\n",
    "        for engine in engines:\n",
    "            if engine['name'] != 'train':\n",
    "                engine['engine'].run(engine['dataloader'])\n",
    "\n",
    "    engines[0]['engine'].add_event_handler(\n",
    "        Events.EPOCH_COMPLETED,\n",
    "        run_tests\n",
    "    )\n",
    "\n",
    "    engines[0]['engine'].run(train_dataloader, max_epochs=20)\n",
    "    TB_LOGGER.close()\n",
    "    wandb.finish()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_str2class = {\n",
    "    # 'SGD': SGD,\n",
    "    # 'SGDScheduleFree': SGDScheduleFree,\n",
    "    'AdamW': AdamW,\n",
    "    'AdamWScheduleFree': AdamWScheduleFree\n",
    "}\n",
    "optimizers= {\n",
    "    # 'SGD': {'momentum': [1e-10, 0.9]},\n",
    "    'AdamW': {'betas': [(1e-10, 0.999), (0.9, 0.999)]},\n",
    "    # 'SGDScheduleFree': {'momentum': [1e-10, 0.9]},\n",
    "    'AdamWScheduleFree': {'betas': [(1e-10, 0.999), (0.9, 0.999)]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([0.4, 0.6]).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8n0eug9h) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c66fa860f474caf96e6d622b126199e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss/train/output</td><td>▂▅▂▄▆█▂▃▄▂▅▄▇▁▃▅▂▆▂▃▅▁▁▂▄▂▅▅▂█▆▃▃▅▂▂▅▂▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss/train/output</td><td>1.58708</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-voice-307</strong> at: <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/8n0eug9h' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/8n0eug9h</a><br/> View project at: <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./pavel-tikhomirov-runs/wandb/run-20241211_224559-8n0eug9h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8n0eug9h). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/main/whitehead/pavel-tikhomirov-runs/wandb/run-20241211_224700-tjez413i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/tjez413i' target=\"_blank\">chocolate-violet-308</a></strong> to <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/tjez413i' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/tjez413i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3bcbfab76e4c62873d52b911075513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/4425]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433737ab65204a3a860a4d87db16039a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/4425]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7be35de7b1457fabc338ce05df5edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/4425]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_kwargs = {\n",
    "    'lr': 4e-6,\n",
    "    'weight_decay': 0.1,\n",
    "}\n",
    "for batch_size in [32, 64, 256, 512, 1024]:\n",
    "    for optimizer_name, optimizer_class in opt_str2class.items():\n",
    "        params = optimizers[optimizer_name]\n",
    "        for param, values in params.items():\n",
    "            for value in values:\n",
    "                kwargs = {param: value}\n",
    "                model = AutoModelForSequenceClassification.from_config(config).to(device)\n",
    "                kwargs.update(default_kwargs)\n",
    "                optimizer = optimizer_class(model.parameters(), **kwargs)\n",
    "                if type(value) in [int, float]:\n",
    "                    str_value = f'{value:.2e}'\n",
    "                else:\n",
    "                    str_value = ';'.join(map(lambda x: f'{x:.2e}', value))\n",
    "                    kwargs[param] = str_value\n",
    "                name = f'{optimizer_name.lower()}_{param}_{str_value}_batch_size_{batch_size}'\n",
    "                kwargs.update({'optimizer': optimizer_name, 'batch_size': batch_size})\n",
    "                train_meta(model, optimizer, name, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([0.4, 0.6]).to(device)\n",
    "# class_weights = None\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = [\n",
    "    ('train', Engine(train), train_dataloader),\n",
    "    ('val', Engine(validation), val_dataloader),\n",
    "    # ('small_length_no_comm_test', Engine(validation), test_no_com_small_length_dataloader),\n",
    "    # ('big_length_joint_test', Engine(validation), test_big_length_dataloader),\n",
    "    # ('big_length_only_comm_test', Engine(validation), test_only_com_dataloader)\n",
    "    ]\n",
    "\n",
    "engines = [dict(zip(['name', 'engine', 'dataloader'], engine)) for engine in engines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForSequenceClassification.from_config(config).to(device)\n",
    "optimizer = SGD(model.parameters(), lr=3e-4) ## config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/main/whitehead/pavel-tikhomirov-runs/wandb/run-20241210_213234-vbkw35ra</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/vbkw35ra' target=\"_blank\">gallant-cherry-273</a></strong> to <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/vbkw35ra' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/vbkw35ra</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x7feb42142590>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TB_LOGGER = TensorboardLogger(log_dir=f\"./experiments/{str(uuid1())}\")\n",
    "WANDB_LOGGER = WandBLogger(\n",
    "    entity='ml-in-algebraic-topology',\n",
    "    project='whitehead',\n",
    "    config={\"optimizer_name\": 'SGD', \"momentum_name\": \"momentum\", \"momentum_value\": 0.9},\n",
    "    tags=[\"optimization\"],\n",
    "    job_type='train'\n",
    ")\n",
    "\n",
    "for engine in engines:\n",
    "\n",
    "    if engine['name'] == 'train':\n",
    "        TB_LOGGER.attach_output_handler(\n",
    "            engine['engine'],\n",
    "            event_name=Events.ITERATION_COMPLETED,\n",
    "            tag=f'loss/{engine[\"name\"]}',\n",
    "            output_transform = lambda output: output['loss']\n",
    "        )\n",
    "        WANDB_LOGGER.attach(\n",
    "            engine['engine'],\n",
    "            log_handler=OutputHandler(\n",
    "                tag=f'loss/{engine[\"name\"]}',\n",
    "                output_transform = lambda output: output['loss'],\n",
    "            ),\n",
    "            event_name=Events.ITERATION_COMPLETED\n",
    "        )\n",
    "    \n",
    "    Accuracy(output_transform=output_transform).attach(engine['engine'], \"accuracy\")\n",
    "\n",
    "    TB_LOGGER.attach_output_handler(\n",
    "        engine['engine'],\n",
    "        event_name=Events.EPOCH_COMPLETED,\n",
    "        tag=f'accuracy/{engine[\"name\"]}',\n",
    "        metric_names=[\"accuracy\"],\n",
    "        global_step_transform=global_step_from_engine(engines[0]['engine']),\n",
    "    )\n",
    "    WANDB_LOGGER.attach(\n",
    "        engine['engine'],\n",
    "        log_handler=OutputHandler(\n",
    "            tag=f'accuracy/{engine[\"name\"]}',\n",
    "            metric_names = [\"accuracy\"],\n",
    "            global_step_transform=lambda *_: engines[0]['engine'].state.iteration\n",
    "        ),\n",
    "        event_name=Events.EPOCH_COMPLETED\n",
    "    )\n",
    "\n",
    "ProgressBar().attach(engines[0]['engine'], output_transform = lambda output: {\"loss\": output['loss']})\n",
    "\n",
    "def run_tests():\n",
    "    for engine in engines:\n",
    "        if engine['name'] != 'train':\n",
    "            engine['engine'].run(engine['dataloader'])\n",
    "\n",
    "engines[0]['engine'].add_event_handler(\n",
    "    Events.EPOCH_COMPLETED,\n",
    "    run_tests\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3bf8941d7c4b878b7b3fcd74ea9796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/62]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf264e5847c4ec89dd2442935686443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/62]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff60b10e396341a591ac7b53bc2d136d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/62]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1810eab65337462c972701198570a8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/62]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c77e32f15a64b1b96a75dd0ed39af6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/train/accuracy</td><td>▁███</td></tr><tr><td>accuracy/val/accuracy</td><td>▁▁▁▁</td></tr><tr><td>loss/train/output</td><td>▇▅▂▁▇▄▄▃▃▇▄▆▆▃▆▃▂▅▄▆▆▁▄▄▃▃▆▄▃▅▁█▃▂▂▂▆▅▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/train/accuracy</td><td>0.75</td></tr><tr><td>accuracy/val/accuracy</td><td>0.75</td></tr><tr><td>loss/train/output</td><td>0.64451</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gallant-cherry-273</strong> at: <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/vbkw35ra' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/vbkw35ra</a><br/> View project at: <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./pavel-tikhomirov-runs/wandb/run-20241210_213234-vbkw35ra/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "engines[0]['engine'].run(val_dataloader, max_epochs=4)\n",
    "TB_LOGGER.close()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
